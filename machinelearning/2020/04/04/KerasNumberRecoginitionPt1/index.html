<!DOCTYPE html>
<html lang=" en "><head>
  <meta charset="utf-8">
  <title>Mike Meldgaard - Software Developer / Datamatiker Student</title>
  <meta http-equip="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Software Developer">
  <link rel="stylesheet" href="https://double-em.github.io/assets/css/main.css" />
  <link rel="stylesheet" href="https://double-em.github.io/assets/css/custom-style.css" />
  <link rel="icon" href="https://double-em.github.io/assets/img/favicon.ico" type="image/gif" sizes="16x16">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.2/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
    integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css"
    integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css"
    integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">
  <!-- Including Snipcart -->
  <link rel="stylesheet" href="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.css" />
  <!-- Including InstantSearch.js library and styling -->
  <!--<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.20.1/moment.min.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">
  <link rel="stylesheet" type="text/css"
    href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch-theme-algolia.min.css">
  <script>
    (function (d, h, m) {
      var js, fjs = d.getElementsByTagName(h)[0];
      if (d.getElementById(m)) { return; }
      js = d.createElement(h); js.id = m;
      js.onload = function () {
        window.makerWidgetComInit({
          position: "right",
          widget: "ofeeof264otl2l5g-zspk40eq2gaomj2n-higi2qphmveubksi"
        })
      };
      js.src = "https://makerwidget.com/js/embed.js";
      fjs.parentNode.insertBefore(js, fjs)
    }(document, "script", "dhm"))
  </script>-->

  

</head><body>
    <div class="container-fluid"><header>

    <div class="col-lg-12">
        <div class="row">
            <div class="col-md-2 center">
                <a href="/">
                    <img src="/assets/img/noimage.jpg" class="profile-img">
                </a>
            </div>
          
            <div class="col-md-4" id="author_details">
                <h1 class="profile-name"> Mike Meldgaard</h1>
                <p class="profile-bio"> Software Developer / Datamatiker Student</p>
                <p class="profile-links">
                    
                    
                    
                    
                    
                    <a class="social-link" href="http://github.com/Zxited">
                        <i class="fab fa-github"></i>
                    </a>
                    
                    
                    
                    
                </p>

            </div>
            <div class="col-md-6 center">
     
                    <ul class="nav justify-content-end" id="navigation">
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/">About</a>
                    </li>
                     
                    <li class="nav-item">
                        <a class="nav-link" href="/blog">Portefølje</a>
                    </li>
                     
                     <!--<li class="nav-item">
                         <a class="nav-link" href="https://double-em.github.io/search/"><i class="fa fa-search" aria-hidden="true"></i></a>
                     </li>-->
                     <!--<li class="nav-item">
                         <button class="header__checkout snipcart-checkout">

                                <svg width="31" height="27" viewBox="0 0 31 27" fill="none" xmlns="http://www.w3.org/2000/svg">
                                  <path
                                    d="M1.10512 0.368718C0.560256 0.368718 0.118164 0.812066 0.118164 1.35848C0.118164 1.9049 0.560256 2.34824 1.10512 2.34824H4.90887L8.30138 18.4009C8.43503 19.0053 8.83085 19.5079 9.32946 19.5041H25.7788C26.3005 19.5118 26.7799 19.0375 26.7799 18.5143C26.7799 17.9911 26.3006 17.5168 25.7788 17.5245H10.1315L9.71003 15.545H27.095C27.5371 15.5412 27.9547 15.2048 28.0511 14.7718L30.354 4.87412C30.4825 4.29933 29.9852 3.67172 29.3979 3.66786H7.21171L6.6771 1.15221C6.58329 0.71276 6.15921 0.368652 5.7107 0.368652L1.10512 0.368718ZM7.623 5.64746H12.7634L13.2569 8.61674H8.25005L7.623 5.64746ZM14.7785 5.64746H20.9881L20.4946 8.61674H15.2719L14.7785 5.64746ZM23.0031 5.64746H28.1537L27.4649 8.61674H22.5097L23.0031 5.64746ZM8.67181 10.5963H13.5862L14.0797 13.5656H9.29919L8.67181 10.5963ZM15.6009 10.5963H20.1656L19.6721 13.5656H16.0944L15.6009 10.5963ZM22.1807 10.5963H27.0023L26.3135 13.5656H21.6872L22.1807 10.5963ZM12.6197 20.164C10.8141 20.164 9.32979 21.6525 9.32979 23.4632C9.32979 25.2739 10.8141 26.7624 12.6197 26.7624C14.4252 26.7624 15.9095 25.2739 15.9095 23.4632C15.9095 21.6525 14.4252 20.164 12.6197 20.164ZM22.4892 20.164C20.6837 20.164 19.1994 21.6525 19.1994 23.4632C19.1994 25.2739 20.6837 26.7624 22.4892 26.7624C24.2948 26.7624 25.7791 25.2739 25.7791 23.4632C25.7791 21.6525 24.2948 20.164 22.4892 20.164ZM12.6197 22.1435C13.3586 22.1435 13.9356 22.7222 13.9356 23.4632C13.9356 24.2042 13.3586 24.7829 12.6197 24.7829C11.8807 24.7829 11.3037 24.2042 11.3037 23.4632C11.3037 22.7222 11.8807 22.1435 12.6197 22.1435ZM22.4892 22.1435C23.2282 22.1435 23.8052 22.7222 23.8052 23.4632C23.8052 24.2042 23.2282 24.7829 22.4892 24.7829C21.7503 24.7829 21.1733 24.2042 21.1733 23.4632C21.1733 22.7222 21.7503 22.1435 22.4892 22.1435Z"
                                    fill="#9094FF" class="header__checkout-fill"></path>
                                </svg>
                                <span class="snipcart-items-count"></span>
                                <span class="snipcart-total-price"></span>
                              </button>
                        </li>-->
                    </ul>
      
            </div>
        </div>
    </div>

</header><div class="col-lg-12">
          
            <!-- Blog Post Breadcrumbs --><nav aria-label="breadcrumb" role="navigation">
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/blog">Blog</a>
            </li>
            <li class="breadcrumb-item">
                <a href="/blog/categories">Categories</a>
            </li>
            <li class="breadcrumb-item active" aria-current="page">Implementering af Deep Learning med MLP arkitektur i Keras</li>
        </ol>
    </nav>
<div class="row">

        <div class="col-lg-8"><article class="card" itemscope itemtype="http://schema.org/BlogPosting">
    <div class="card-header">
        <!-- <h1 class="post-title" itemprop="name headline">Implementering af Deep Learning med MLP arkitektur i Keras</h1> -->
        <h4 class="post-meta">Implementering af Deep Learning med Multi-later Perceptron i Keras biblioteket for genkendelse af billeder (Keras Number Recognition Del 1).</h4>
        <p class="post-summary">Posted by : 
            <img src="/assets/img/noimage.jpg" class="author-profile-img">
            <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                <span itemprop="name">Mike Meldgaard</span>
            </span> at
            <time datetime="2020-04-04 00:00:00 +0000" itemprop="datePublished">Apr 4, 2020</time>
        </p>
        <span class="disqus-comment-count" data-disqus-identifier="/machinelearning/2020/04/04/KerasNumberRecoginitionPt1/"></span>     
        <div class="post-categories">
            
            Category : 
            <a href="/blog/categories/MachineLearning">MachineLearning</a>
             
        </div>
    </div>

    <div class="card-body" itemprop="articleBody">
        <!--<img class="card-img-top" src="/assets/img/posts/development.png" alt=""> 
        <br/> <br/>-->
        <h1 id="implementering-af-deep-learning-med-mlp-arkitektur-i-keras">Implementering af Deep Learning med MLP arkitektur i Keras</h1>
<p>I dette oplæg vil jeg forklare om, hvornår Neurale Netværk(NN) bør bruges, samtidig med en hurtig forklaring af, hvordan man håndtere en NN opgave. Jeg vil også forklare om og bruge Keras med TenforFlow som backend til, at løse opgaven.</p>

<h2 id="hornår-skal-vi-anvende-neurale-netværk">Hornår skal vi anvende Neurale Netværk?</h2>
<p>Deep learning laver store fremskridt indenfor Machine Learning bl.a. ved, at genkende tale, billeder, data analyse, markeds analyse eller natural language processing (NLP) samt mange flere.</p>

<p>Hvad skal vi så tænke over inden vi løber ud og bruger denne fantastike teknologi?</p>

<ul>
  <li>
    <p><strong>Neurale Netværk kræver klar og informativ data og ofte meget af det.</strong> Dette er fordi vi skal træne netværket og ligesom med mennesker lære den ting ved at gøre det mange gange.</p>
  </li>
  <li>
    <p><strong>Neurale Netværk fungere godt til komplekse problemer,</strong> hvor vi som mennesker har svært ved, at se sammenhængen mellem mange forskellige værdier eller inputs. Dette er fordi Neurale Netværk tilhøre den gruppe af algoritmer kaldet “Representation Learning Algorithms”, som nedbryder komplekse problemer ned i en simplere form, så de kan forståes. Traditionelle “Non-Representation Learning” har det svært ved samme komplekse opgaver.</p>
  </li>
  <li>
    <p><strong>Man skal vælge den rigtige type Neurale Netværk til den givne opgave.</strong> Hver opgave har sit eget twist, så det er op til udvikleren, at løse opgaven effektivt. Det er f.eks. bedst, at bruge RNN til sekvens generations opgaver, eller CNN for billede relateret opgaver. Da der ikke findes en gylden arkitektur til alle opgaver.</p>
  </li>
  <li>
    <p><strong>Neurale Netværk kræver mange computere ressourcer.</strong> Dette er fordi når man træner netværket udføres mange beregninger for, hver vægt eller bias. Dette kan derfor være dyrt og noget der skal tages med i overvejelsen også når man vælger type af Neuralt Netværk. Nogle netværk kan opnå et acceptabel resultat uden, at være det bedste til jobbet, men i stedet være mere effektivt, så det bruger mindre ressourcer. Hvad et acceptabelt resultat er, er noget der bedømmes ud fra opgavens krav.</p>
  </li>
</ul>

<p>Neurale Netværk er en speciel type af Machine Learning (ML) algoritmer.
ML workflow starter ofte med behandling af data, så model byggelse og til sidst model evaluering.</p>

<p>TODO liste for, at håndtere et Neuralt Netværks(NN) problem:</p>
<ul>
  <li>Undersøg om NN giver en fordel over traditionelle algoritmer (Som i overvejelserne ovenover)</li>
  <li>Undersøg hvilke NN arkitekture der er bedst til opgaven.</li>
  <li>Definer NN arkitekturen i det programmeringssprog / bibliotek man har valgt.</li>
  <li>Konverter dataen til den rigtige format og del den op i sektioner / batches.</li>
  <li>Forbehandl dataen i forhold til ens behov.</li>
  <li>Forøg data for, at øge størrelsen og træne bedre modeller.</li>
  <li>Fodre netværket med batches af data.</li>
  <li>Træn netværket og overvåg ændringer i trænings og validerings data sættene.</li>
  <li>Test modellen med et andet data sæt og gem den til fremtidig brug.</li>
</ul>

<h3 id="hvordan-forstår-en-maskine-et-billede">Hvordan forstår en maskine et billede?</h3>
<p>For os som mennesker er det nemt, at se forskellen mellem en bil og en hest og vi forstår hurtigt helheden i billedet. Men en maskine er ikke opvokset med alle de sanser vi har og kan ikke “se” på samme måde vi ser. Et billede for en maskine er et 3D array af tal som repræsentere farve kanalerne for, hver pixel i billedet. Dette fenomen er kendt som “Semantic gap” fordi vi ser forskelligt fra en maskine.</p>

<p>Førhen forsøgte man, at bruge skabeloner, så maskinen bedre kunne forstå det. Disse skabeloner ville indeholder f.eks. ved et ansigt øjnenes placering eller afstand til næsen osv. Dette var ikke holdbart, da man skulle bruge flere og flere skabeloner for, at kunne identificere flere obejekter.</p>

<p>Man senere i 2012 efter et dybt neural netværk vandt ImageNet udfordringen styret mod dybe neurale netværk for mange forskellige netværk.</p>

<p>Forskellige sprog som Python, Lua, Java og Matlab er brugt til, at kode neurale netværk. Sammen med nogle af de mest populære biblioteker til billede opgaver:</p>
<ul>
  <li>Caffe</li>
  <li>DeepLearning4j</li>
  <li>TensorFlow</li>
  <li>Theano</li>
  <li>Torch</li>
</ul>

<p>Vi bruger TensorFlow i dette oplæg.</p>

<h2 id="hvad-er-tensorflow">Hvad er TensorFlow?</h2>
<p>TensforFlow er et open source bibliotek brugt til numerisk beregning. De introducere “tensors” som er et multi-dimensionelt array, som udveksles mellem noderne som repræsentere matematiske operationer. Grundet den fleksible arkitektur kan TensorFlow køres på CPUer eller GPUer i en stationær computer, server eller mobile enheder med et enkelt API.</p>

<p>Fordel ved TensorFlow:</p>
<ul>
  <li>Den har et “flow of tensors”, så man har nemmere ved at visualisere, hver del af en graf.</li>
  <li>Kan trænes på CPU/GPU for distribueret beregning.</li>
  <li>Kan bruges på flere platform som PC, Server og Mobil.</li>
</ul>

<p>TensorFlow v1 workflow:</p>
<ul>
  <li>Byg en beregnings graf ved brug af enhver matematisk operation TensorFlow understøtter.</li>
  <li>Instanser variabler for, at kompilere variablerne defineret tidligere.</li>
  <li>Lav en session.</li>
  <li>Kør grafen i sessionen. Den kompileret graf er vidergiver til sessionen som starter eksekveringen.</li>
  <li>Luk sessionen</li>
</ul>

<p>Lig mærke til det er for “v1”, da der er kommet en “v2” som simplificere en del. Der eksitere ikke længere en session, da den er erstattet med et kald til en funktion. Det er ikke nødvendigt at instanere variablerne, da de behandles som i normal Python kode, så placeholders er væk.</p>

<p>TensorFlow v2 workflow:</p>
<ul>
  <li>Definer variabler.</li>
  <li>Lav / definer modellen.</li>
  <li>Kompiler modellen.</li>
  <li>Træn og test modellen.</li>
</ul>

<p>Overni disse ændringer, er der også kommet en @tf.function, som kan sættes over en funktion for højere ydeevne.</p>

<h2 id="hvad-er-keras">Hvad er Keras?</h2>
<p>Keras er et high-level neuralt netværks API skrevet i Python og kan køre på toppen af Tensorflow, CNTK eller Theano. Det er er lavet med fokus på hurtig eksperimentering, så man kan gå fra idé til resultat med så små forsinkelser som muligt.</p>

<p>Keras er brugt som et deep learning library når:
	1. Man har brug for nemme og hurtige protyper igennem brugervenlighed, modularitet og evnen til udvidelse.
	2. Support for både Convolutional- og Recurrent neurale netværk samt en kombination af begge.
Køre glidende på både CPU og GPU.</p>

<p>Keras tager de low-level biblioteker den køre på og udgiver deres interface på en mere “brugervenlig” måde. Dette kommer dog også med nogle begrænsninger, da Keras ikke rigtig kan gå ud over dens backend / low-level bibliotek den køre på, som kan gøre det svært, at implementere sine egne operationer grundet den mindre fleksibilitet på den front.</p>

<h2 id="opsætning-af-vores-miljø">Opsætning af vores miljø</h2>
<p>Vi vil i vores program skulle bruge en række biblioteker:</p>

<ul>
  <li>numpy</li>
  <li>Pandas</li>
  <li>Scipy og Pillow(Brugt til Scipy.misc.imread), men Scipy.misc.imread er udagået, så vi bruger imageio i stedet.</li>
  <li>imageio</li>
  <li>scikit-learn (sklearn)</li>
</ul>

<p>Jeg bruger følgende pakker:</p>
<ul>
  <li>numpy==1.18.2</li>
  <li>pandas==0.25.3</li>
  <li>pandas-datareader==0.8.0</li>
  <li>scikit-learn==0.22.2.post1</li>
  <li>imageio==2.8.0</li>
</ul>

<p>Bemærk: Hvis du gerne vil se alle dine pakker installeret:
<code class="language-plaintext highlighter-rouge">pip freeze</code>
Hvis man vil indsætte alle de pakker man bruger som en del af dem der skal installeres når containeren køre(Hvis man har konfiguret det i ens Dockerfile), kan man overføre dem til en tekstfil:
<code class="language-plaintext highlighter-rouge">pip freeze &gt; requirements.txt</code>
Som var en teknik jeg brugte i starten, hvor jeg brugte TensorFlows eget image. Indtil jeg byggede mit eget image, med de rigtige pakker, baseret på det image jeg brugte fra TensorFlow.</p>

<p>Samtidig skal vi også have installeret TensorFlow(tf), men dog ikke Keras, da vi bruger tf.keras i stedet, som er Keras indbygget i TensorFlow 2.0 der er bedre vedligeholdt og tilbyder bedre integration med TensorFlows funktioner og features.</p>

<p>Afhængig om man køre programmet lokalt eller i en container skal man installere pakkerne lokalt eller sørge for ens image har dem.</p>

<p>Bemærk det er nemmere, at have GPU understøttelse ved brug af containere, da CUDA Tools ikke er nødvendig for understøttelsen i containeren.</p>

<p>Jeg har gjort det, at jeg har taget TensorFlows docker image med gpu og python 3 support og installeret de nødvendige pakker i det image, så jeg bagefter kunne lave mit eget image som kunnes oploades til Docker Hub til senere brug.</p>

<p>For at bruge ens GPU til træning af netværket, skal man have nvidia og cuda drivers intalleret, sammen med nvidia-docker eller nvidia-docker2 som har swarm support og er nyere, så den bruger jeg.</p>

<p>Når man skal køre en container i docker med gpu, bruger man “–runtime=nvidia” eller “–gpus all” flagene.</p>

<p>Man kan teste om man kan køre containere med gpu understøttelse ved, at køre:
<code class="language-plaintext highlighter-rouge">sudo docker run --rm --runtime=nvidia -ti nvidia/cuda</code>
Og så køre kommandoen
<code class="language-plaintext highlighter-rouge">nvidia-smi</code></p>

<p>Et eksempel output:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo docker run --rm --runtime=nvidia -ti nvidia/cuda
roo@2d0aad394700:/# nvidia-smi
Sat Apr  4 11:19:25 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Geforce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |
| 16%   55C    P0    31W / 151W |    7880MiB / 8119MiB |     12%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|                                                                             |
+-----------------------------------------------------------------------------+
</code></pre></div></div>

<p>I en docker-compose kan man også definere runtime til at være nvidia.</p>

<p>For at starte mit program endte jeg ud i, at lave en scripts fil i stedet for den indbygget debug launch metode i visual studio code. Grundet at det gav mig fuld kontrol af containeren og jeg kunne sætte –gpus flaget:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build -t mmgamesfull/kerasnumberrecognition:latest .
docker run -it --rm --gpus all mmgamesfull/kerasnumberrecognition:latest
</code></pre></div></div>

<p>Efter at have løst alle de forskellige fejl omkring udgået pakker og nvidia driver fejl osv. Kan vi komme videre.</p>

<h2 id="løs-opgaven">Løs opgaven</h2>
<p>Trin for trin for, at løse opgaven.
Data kan findes her: <a href="https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/">https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/</a></p>

<h3 id="trin-1">Trin 1</h3>
<p>Importer alle de nødvendige biblioteker.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import numpy as np
import pandas as pd

from imageio import imread
from sklearn.metrics import accuracy_score

import tensorflow as tf
from tensorflow import keras
</code></pre></div></div>

<p>Kontroller modellens tilfældighed ved, at sætte et seed.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>seed = 128
rng = np.random.RandomState(seed)
</code></pre></div></div>

<p>Sæt stierne til ressourcerne.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>root_dir = os.path.abspath('../..')
data_dir = os.path.join(root_dir, 'data')
</code></pre></div></div>

<p>Tjek om stierne eksistere.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>os.path.exists(root_dir)
os.path.exists(data_dir)
</code></pre></div></div>

<h3 id="trin-2">Trin 2</h3>
<p>Læs data sættene.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train = pd.read_csv(os.path.join(data_dir, 'train.csv'))
test = pd.read_csv(os.path.join(data_dir, 'test.csv'))

sample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))
</code></pre></div></div>

<p>Hvis man vil se toppen af ens datafil kan man udskrive den med:
<code class="language-plaintext highlighter-rouge">train.head()</code></p>

<p>Hvert billede er repræsenteret som et numpy array.
Så for nemmere, at håndtere dataen opbevare vi billederne i numpy arrays.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>temp = []
for img_name in train.filename:
    image_path = os.path.join(data_dir, 'Images', 'train', img_name)
    
    img = imread(image_path, as_gray=True)
    img = img.astype('float32')
    temp.append(img)

    image_train_count += 1

train_x = np.stack(temp)

train_x /= 255.0
train_x = train_x.reshape(-1, 784).astype('float32')

image_test_count = 0
temp = []
for img_name in test.filename:
    image_path = os.path.join(data_dir, 'Images', 'test', img_name)
    img = imread(image_path, as_gray=True)
    img = img.astype('float32')
    temp.append(img)

    image_test_count += 1

test_x = np.stack(temp)

test_x /= 255.0
test_x = test_x.reshape(-1, 784).astype('float32')
</code></pre></div></div>

<p>Bemærk vi bruger as_gray=True som essentielt er det samme som flatten=True i Scipy. Vi gør det fordi vi skal kun bruge det som sort-hvid og derfor fjerner vi de andre farvekanaler som giver os end del mindre datapunkter, da farven ikke har noget, at gøre med billedet i denne omgang.</p>

<p>Funktionen “np.stack(temp)” er en måde vi kan tage vores billede array og stable dem til den rigtige form / dimension.</p>

<p>Vi omdanner så vores markater til en matrix af klasser. Som bruges ved f.eks. crossentropy.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train_y = keras.utils.to_categorical(train.label.values)
</code></pre></div></div>

<p>Ved ML kan det være et problem, at verificere, at ens netværk køre rigtigt. Derfor splitter vi træningsdataen op, så vi får et valideringssæt og et træningsæt.
Vi sætter splittet til 70:30, hvor det 70% er træningssættet.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>split_size = int(train_x.shape[0]*0.7)

train_x, val_x = train_x[:split_size], train_x[split_size:]

train_y, val_y = train_y[:split_size], train_y[split_size:]

</code></pre></div></div>

<p>Det samme gør vi for vores markater i sættet.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train.label.loc[split_size:]
</code></pre></div></div>

<p>Bemærk at .ix index’eren er udgået i pandas og blevet erstattet med .loc for label index og .iloc for positions index grundet, det forvirrede brugere, at den kunne begge.</p>

<h3 id="trin-3">Trin 3</h3>
<p>Vi kommer nu til punktet, hvor vi skal have bygget en model. Vi bruger 3 lag denne gang som er input, hidden, output. Antallet af neuroner ved input og output er fastlåst, da vores input er et 28x28 billede som giver 784 neuroner og vores output er tallene 0 - 9, som så giver 10 output neuroner. Vi vælger 50 for det gemte lag, men det kan man optimere, hvis man synes.</p>

<p>Vi starter med, at definere variablerne.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input_num_units = 784
hidden_num_units = 50
output_num_units = 10

epochs = 5
batch_size = 128
</code></pre></div></div>

<p>Så importere vi modulerne vi skal bruge for vores model og bygger en model som beskrevet oppe over. Vu bruger “relu” som aktiverings funktion og softmax til vores output, da vi gerne vil have en sandsynlighed for, hvilket af de 10 tal den tror det er på billedet.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(hidden_num_units, input_dim=input_num_units, activation='relu'),
    Dropout(dropout_ratio),
    Dense(hidden_num_units, input_dim=hidden_num_units, activation='relu'),
    Dense(output_num_units, input_dim=hidden_num_units, activation='softmax'),
])
</code></pre></div></div>
<p>Bemærk Dense() bruger ikke længere “output_dim=” for, at definere outputtets dimensioner, men det hedder i stedet “units” og kan bare skriver som det første tal.</p>

<p>Efter første lag i modellen er det teknisk set ikke nødvendigt, at definere input størrelsen længere. Men jeg har gjort dette for, at det er nemmere, at forstå.</p>

<p>Vi bruger “Adam” som vores optimerings funktions algoritme, som er en effektiv variant af “Gradient Decent” algoritmen. Tab bliver beregnet med kategorisk crossentropy.</p>

<p>Vi kompilere nu vores model med de ønskede funtioner.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre></div></div>

<p>Vi kan nu træne vores model!</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>trained_model = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))
</code></pre></div></div>
<p>Bemærk førhen var “epochs” parameteren kaldet “np_epochs”.</p>

<p>Ved kørsel af programmet skulle vi gerne få et output svarende til følgende:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1
Epoch 1/5
2020-04-04 14:55:55.946689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
268/268 - 1s - loss: 1.0428 - accuracy: 0.6165 - val_loss: 0.3044 - val_accuracy: 0.9229
2
Epoch 2/5
268/268 - 1s - loss: 0.3171 - accuracy: 0.9208 - val_loss: 0.2010 - val_accuracy: 0.9490
3
Epoch 3/5
268/268 - 1s - loss: 0.2372 - accuracy: 0.9428 - val_loss: 0.1995 - val_accuracy: 0.9535
4
Epoch 4/5
268/268 - 1s - loss: 0.2145 - accuracy: 0.9491 - val_loss: 0.1738 - val_accuracy: 0.9599
5
Epoch 5/5
268/268 - 1s - loss: 0.1888 - accuracy: 0.9578 - val_loss: 0.1626 - val_accuracy: 0.9597
</code></pre></div></div>

<p>Tallene 1 - 5 imellem linjerne er vores “EpochCount()” klasse.</p>

<p><strong>(VALGFRIT)</strong>
Hvis man køre det i en container eller remote, vil man nogle gange ikke kunne se, hvor langt den er nået i trænings processen. Det jeg har gjort for, at få en smule feedback fra den er, at jeg har lavet en Callback klasse, som udskriver, hvilken iteration den er igang med.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class EpochCount(keras.callbacks.Callback):
    def on_epoch_begin(self, epoch, logs={}):
        print(epoch + 1)
</code></pre></div></div>

<p>For at bruge vores Callback klasse “EpochCount()” skal vi have en instans af den og give den instans til model.fit() funktionen.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch_count = EpochCount()

trained_model = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y), verbose=2, callbacks=[epoch_count])

</code></pre></div></div>

<h3 id="trin-4">Trin 4</h3>
<p>Vi skal nu evaluere vores model.
Der findes flere måder, at evaluere ens model. Hvis man har et stort datasæt, så ville man splitte dataen op ligesom vi gjorde med validerings dataen, så man har et test sæt og et trænings sæt og derefter splitte træningsdataen op i validerings sæt og trænings sæt, for vi stadig har noget validering efter, hver epoch. Hvor man så efter, at have trænet sin model ville kunne teste den op mod ens test sæt, som netværket ikke kender til, da det er et sæt for sig selv og få en præcision på baggrund af test sættet. Det er vigtigt, at man ikke tester på den data netværket allerede har trænet på, da den kender til sættet i forvejen og det er derfor svært, at fange ting som overfitting.</p>

<p>I det her tilfælde, der på siden, hvor vi fik dataen er der en submission form, hvor man kan uploade sin .csv fil når ens netværk har gået det igennem, for at få et tal på, hvor præcist netværket har klaret det.</p>

<p>Så vi tager vores netværk og laver forudsigelse på vores test sæt.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pred = np.argmax(model.predict(test_x), axis=-1)
</code></pre></div></div>
<p>Bemærk at model.predict_classes er udgået og forsvinder i fremtiden fra biblioteket.
Man skal i stedet bruge “np.argmax(model.predict(x), axis=-1)” til multiclass classification predictions ved f.eks. softmax() som giver en sandsynligheds matrix.
Ellers ved binær klassifikation (Ja eller Nej / True or False) f.eks. Sigmoid() som giver en værdi mellem 0 og 1 bruger man “model.predict(x) &gt; 0.5).astype(“int32”)”.</p>

<p>Vi tager så vores submissions fil og definere, hvilke værdier der skal være i hver kolonne og udskriver den til vores data mappe som .csv igen.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sample_submission.filename = test.filename
sample_submission.label = pred

sample_submission.to_csv(os.path.join(data_dir, "test.csv"), index=False)
</code></pre></div></div>

<p>Hvis programmet køre lokalt på ens computer, vil den ligge lokalt på den mappe man har valgt. Hvis man dog køre programmet i en docker container, vil det være nødvendigt, at trække filen ud af containeren og ned på en lokale computer. Dette kan gøres ved:
<code class="language-plaintext highlighter-rouge">docker cp CONTAINER_NAME_GOES_HERE:/path/to/test.csv /path/to/location/</code></p>

<p>Som i mit tilfælde med denne container vil se sådan her ud:
<code class="language-plaintext highlighter-rouge">docker cp kerasnumberrecognition:/data/test.csv .</code>
Punktummet i slutningen betyder, at den skal gemme filen i den mappe jeg står i med min terminal.</p>

<p>Man kan nu uploade sin fil til testeren og se sit flotte resultat. Men man kan også fin-tune sit netværk med flere lag og flere neuroner, som jeg kommer ind på en anden gang.</p>

<p>Vi har nu lært at implementere et Multi-layer Perceptron neuralt netværk, som er måske den mest simple form for neuralt netværk. Der findes mange andre netværk, som man ville kunne prøve og få bedre resultater med, som jeg vil demonstere også en anden gang.</p>

<h2 id="kilder">Kilder</h2>
<ul>
  <li>
    <p>Introduktion til implementering af NN i TensorFlow<br /><a href="https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/">https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/</a></p>
  </li>
  <li>
    <p>Brug og optimatisering af NN med Keras<br /><a href="https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/#nine">https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/#nine</a></p>
  </li>
  <li>
    <p>Migrering fra TensorFlow v1 til v2<br /><a href="https://www.tensorflow.org/guide/migrate">https://www.tensorflow.org/guide/migrate</a></p>
  </li>
  <li>
    <p>imageio imread dokumentation<br /><a href="https://imageio.readthedocs.io/en/stable/userapi.html#imageio.help">https://imageio.readthedocs.io/en/stable/userapi.html#imageio.help</a></p>
  </li>
  <li>
    <p>Overgang fra Scipy imread til imageio imread<br /><a href="https://imageio.readthedocs.io/en/stable/scipy.html">https://imageio.readthedocs.io/en/stable/scipy.html</a></p>
  </li>
  <li>
    <p>TensorFlow v2 model.fit<br /><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit">https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit</a></p>
  </li>
  <li>
    <p>Brug af tf.keras i stedet for Keras<br /><a href="https://keras.io/#multi-backend-keras-and-tfkeras">https://keras.io/#multi-backend-keras-and-tfkeras</a></p>
  </li>
  <li>
    <p>TensorFlow Docker Hub images<br /><a href="https://hub.docker.com/r/tensorflow/tensorflow">https://hub.docker.com/r/tensorflow/tensorflow</a></p>
  </li>
  <li>
    <p>Brug af GPUer i Containers<br /><a href="https://devblogs.nvidia.com/gpu-containers-runtime/">https://devblogs.nvidia.com/gpu-containers-runtime/</a></p>
  </li>
  <li>
    <p>Docker Runtime options<br /><a href="https://docs.docker.com/config/containers/resource_constraints/#access-an-nvidia-gpu">https://docs.docker.com/config/containers/resource_constraints/#access-an-nvidia-gpu</a></p>
  </li>
  <li>
    <p>Dockerfile cheat sheet<br /><a href="https://kapeli.com/cheat_sheets/Dockerfile.docset/Contents/Resources/Documents/index">https://kapeli.com/cheat_sheets/Dockerfile.docset/Contents/Resources/Documents/index</a></p>
  </li>
  <li>
    <p>numpy.stack<br /><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html?highlight=numpy%20stack#numpy.stack">https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html?highlight=numpy%20stack#numpy.stack</a></p>
  </li>
  <li>
    <p>Keras Utils to_categorical<br /><a href="https://keras.io/utils/">https://keras.io/utils/</a></p>
  </li>
  <li>
    <p>pandas IX indexer udgået<br /><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated">https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated</a></p>
  </li>
  <li>
    <p>Keras Sequential model<br /><a href="https://keras.io/getting-started/sequential-model-guide/">https://keras.io/getting-started/sequential-model-guide/</a></p>
  </li>
  <li>
    <p>tf.keras.layers.Dense<br /><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense</a></p>
  </li>
  <li>
    <p>Keras Callbacks<br /><a href="https://keras.io/callbacks/">https://keras.io/callbacks/</a></p>
  </li>
  <li>
    <p>tf.keras.callbacks.Callback<br /><a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback">https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback</a></p>
  </li>
  <li>
    <p>tf.model.predict<br /><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict">https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict</a></p>
  </li>
  <li>
    <p>tf predict_classes source code<br /><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/sequential.py#L324-L342">https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/sequential.py#L324-L342</a></p>
  </li>
  <li>
    <p>Copy file from docker container<br /><a href="https://stackoverflow.com/questions/22049212/copying-files-from-docker-container-to-host">https://stackoverflow.com/questions/22049212/copying-files-from-docker-container-to-host</a></p>
  </li>
</ul>
 
    </div>

    <div id="disqus_thread"></div>

</article>
<script>
    var disqus_config = function () {
        this.page.url = "https://double-em.github.io/machinelearning/2020/04/04/KerasNumberRecoginitionPt1/"; /* Replace PAGE_URL with your page's canonical URL variable */
        this.page.identifier = "/machinelearning/2020/04/04/KerasNumberRecoginitionPt1"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */
    };


    (function () { /* DON'T EDIT BELOW THIS LINE */
        var d = document,
            s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript></div>
<div class="col-lg-4">
    <div class="card">
        <div class="card-header"> About </div>
        <div class="card-body text-dark">
            <!-- Your Bio -->
            <p> Software Developer / Datamatiker 4. Sem. Student, Produktgruppe 15, Procesvejledning 8, ERFA Machine Learning 2, ERFA DevOps</p><!-- Place this tag where you want the button to render. -->
<a class="github-button" href="https://github.com/zxited" data-size="large" data-show-count="true" aria-label="Star Zxited on GitHub">Star</a></div>
    </div>
    <div class="card">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <!-- sidebar-horizontal-1 -->
        <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-7259836434848202"
             data-ad-slot="7549410045"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
        <script>
             (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
    </div>
    <div class="card">
        <div class="card-header">Categories </div>
        <div class="card-body text-dark">
             
            <div id="#Laeringsplaner"></div>
            <li class="tag-head">
                <a href="/blog/categories/Laeringsplaner">Laeringsplaner</a>
            </li>
            <a name="Laeringsplaner"></a>

             
            <div id="#MachineLearning"></div>
            <li class="tag-head">
                <a href="/blog/categories/MachineLearning">MachineLearning</a>
            </li>
            <a name="MachineLearning"></a>

             
            <div id="#DevOps"></div>
            <li class="tag-head">
                <a href="/blog/categories/DevOps">DevOps</a>
            </li>
            <a name="DevOps"></a>

            </div>
    </div>
</div></div> <!-- End of row-->
    

    

        </div>
<footer>

    <!--<p> Powered by<a href="https://devlopr.netlify.com/readme"> devlopr jekyll</a>. Hosted at <a href="https://pages.github.com">Github</a>. Subscribe via
        <a href=" /feed.xml ">RSS</a>
    </p>-->

    <p>&copy;2020 - Project blog for school performance reporting.</p>

</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
</div>
</body>

<div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div>
<script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script>
</html>
