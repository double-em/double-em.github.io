<!DOCTYPE html>
<html lang=" en "><head>
  <meta charset="utf-8">
  <title>Mike Meldgaard - Software Developer / Datamatiker Student</title>
  <meta http-equip="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Software Developer">
  <link rel="stylesheet" href="https://double-em.github.io/assets/css/main.css" />
  <link rel="stylesheet" href="https://double-em.github.io/assets/css/custom-style.css" />
  <link rel="icon" href="https://double-em.github.io/assets/img/favicon.ico" type="image/gif" sizes="16x16">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.2/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
    integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css"
    integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css"
    integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">
  <!-- Including Snipcart -->
  <link rel="stylesheet" href="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.css" />
  <!-- Including InstantSearch.js library and styling -->
  <!--<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.20.1/moment.min.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">
  <link rel="stylesheet" type="text/css"
    href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch-theme-algolia.min.css">
  <script>
    (function (d, h, m) {
      var js, fjs = d.getElementsByTagName(h)[0];
      if (d.getElementById(m)) { return; }
      js = d.createElement(h); js.id = m;
      js.onload = function () {
        window.makerWidgetComInit({
          position: "right",
          widget: "ofeeof264otl2l5g-zspk40eq2gaomj2n-higi2qphmveubksi"
        })
      };
      js.src = "https://makerwidget.com/js/embed.js";
      fjs.parentNode.insertBefore(js, fjs)
    }(document, "script", "dhm"))
  </script>-->

  

</head><body>
    <div class="container-fluid"><header>

    <div class="col-lg-12">
        <div class="row">
            <div class="col-md-2 center">
                <a href="/">
                    <img src="/assets/img/noimage.jpg" class="profile-img">
                </a>
            </div>
          
            <div class="col-md-4" id="author_details">
                <h1 class="profile-name"> Mike Meldgaard</h1>
                <p class="profile-bio"> Software Developer / Datamatiker Student</p>
                <p class="profile-links">
                    
                    
                    
                    
                    
                    <a class="social-link" href="http://github.com/Zxited">
                        <i class="fab fa-github"></i>
                    </a>
                    
                    
                    
                    
                </p>

            </div>
            <div class="col-md-6 center">
     
                    <ul class="nav justify-content-end" id="navigation">
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/">About</a>
                    </li>
                     
                    <li class="nav-item">
                        <a class="nav-link" href="/blog">Portefølje</a>
                    </li>
                     
                     <!--<li class="nav-item">
                         <a class="nav-link" href="https://double-em.github.io/search/"><i class="fa fa-search" aria-hidden="true"></i></a>
                     </li>-->
                     <!--<li class="nav-item">
                         <button class="header__checkout snipcart-checkout">

                                <svg width="31" height="27" viewBox="0 0 31 27" fill="none" xmlns="http://www.w3.org/2000/svg">
                                  <path
                                    d="M1.10512 0.368718C0.560256 0.368718 0.118164 0.812066 0.118164 1.35848C0.118164 1.9049 0.560256 2.34824 1.10512 2.34824H4.90887L8.30138 18.4009C8.43503 19.0053 8.83085 19.5079 9.32946 19.5041H25.7788C26.3005 19.5118 26.7799 19.0375 26.7799 18.5143C26.7799 17.9911 26.3006 17.5168 25.7788 17.5245H10.1315L9.71003 15.545H27.095C27.5371 15.5412 27.9547 15.2048 28.0511 14.7718L30.354 4.87412C30.4825 4.29933 29.9852 3.67172 29.3979 3.66786H7.21171L6.6771 1.15221C6.58329 0.71276 6.15921 0.368652 5.7107 0.368652L1.10512 0.368718ZM7.623 5.64746H12.7634L13.2569 8.61674H8.25005L7.623 5.64746ZM14.7785 5.64746H20.9881L20.4946 8.61674H15.2719L14.7785 5.64746ZM23.0031 5.64746H28.1537L27.4649 8.61674H22.5097L23.0031 5.64746ZM8.67181 10.5963H13.5862L14.0797 13.5656H9.29919L8.67181 10.5963ZM15.6009 10.5963H20.1656L19.6721 13.5656H16.0944L15.6009 10.5963ZM22.1807 10.5963H27.0023L26.3135 13.5656H21.6872L22.1807 10.5963ZM12.6197 20.164C10.8141 20.164 9.32979 21.6525 9.32979 23.4632C9.32979 25.2739 10.8141 26.7624 12.6197 26.7624C14.4252 26.7624 15.9095 25.2739 15.9095 23.4632C15.9095 21.6525 14.4252 20.164 12.6197 20.164ZM22.4892 20.164C20.6837 20.164 19.1994 21.6525 19.1994 23.4632C19.1994 25.2739 20.6837 26.7624 22.4892 26.7624C24.2948 26.7624 25.7791 25.2739 25.7791 23.4632C25.7791 21.6525 24.2948 20.164 22.4892 20.164ZM12.6197 22.1435C13.3586 22.1435 13.9356 22.7222 13.9356 23.4632C13.9356 24.2042 13.3586 24.7829 12.6197 24.7829C11.8807 24.7829 11.3037 24.2042 11.3037 23.4632C11.3037 22.7222 11.8807 22.1435 12.6197 22.1435ZM22.4892 22.1435C23.2282 22.1435 23.8052 22.7222 23.8052 23.4632C23.8052 24.2042 23.2282 24.7829 22.4892 24.7829C21.7503 24.7829 21.1733 24.2042 21.1733 23.4632C21.1733 22.7222 21.7503 22.1435 22.4892 22.1435Z"
                                    fill="#9094FF" class="header__checkout-fill"></path>
                                </svg>
                                <span class="snipcart-items-count"></span>
                                <span class="snipcart-total-price"></span>
                              </button>
                        </li>-->
                    </ul>
      
            </div>
        </div>
    </div>

</header><div class="col-lg-12">
          
            <!-- Blog Post Breadcrumbs --><nav aria-label="breadcrumb" role="navigation">
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/blog">Blog</a>
            </li>
            <li class="breadcrumb-item">
                <a href="/blog/categories">Categories</a>
            </li>
            <li class="breadcrumb-item active" aria-current="page">Forståelse Recurrent Neural Network (RNN)</li>
        </ol>
    </nav>
<div class="row">

        <div class="col-lg-8"><article class="card" itemscope itemtype="http://schema.org/BlogPosting">
    <div class="card-header">
        <!-- <h1 class="post-title" itemprop="name headline">Forståelse Recurrent Neural Network (RNN)</h1> -->
        <h4 class="post-meta">Forståelse af RNN samt dens problemer med Vanishing og Exploding Gradient (27/3 - 1/4)</h4>
        <p class="post-summary">Posted by : 
            <img src="/assets/img/noimage.jpg" class="author-profile-img">
            <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                <span itemprop="name">Mike Meldgaard</span>
            </span> at
            <time datetime="2020-03-27 00:00:00 +0000" itemprop="datePublished">Mar 27, 2020</time>
        </p>
        <span class="disqus-comment-count" data-disqus-identifier="/machinelearning/2020/03/27/Understanding_RNN/"></span>     
        <div class="post-categories">
            
            Category : 
            <a href="/blog/categories/MachineLearning">MachineLearning</a>
             
        </div>
    </div>

    <div class="card-body" itemprop="articleBody">
        <!--<img class="card-img-top" src="/assets/img/posts/learn.png" alt=""> 
        <br/> <br/>-->
        <h2 id="forståelse-af-rnn">Forståelse af RNN</h2>

<h3 id="hvad-er-rnn">Hvad er RNN?</h3>
<p>RNN står for Recurrent Neural Network og er kommet til pga. behovet for at håndtere varieret typer og længder af båede input og output værdier. Dvs. RNN kan håndtere sekvens input aka. den kan holde en gennemgående relation til forrige inputs i en sekvens af data for at skabe et samlet output. Dette kan være et time series problem, hvor tidspunktet / rækkefølgen for dataen i sekvensen har noget at gøre med den næste værdi. F.eks. i en sætning, som “Jeg køber ind” har rækkefølgen af bogstaverne / ordene stor betydning for forståelsen af sætningen.</p>

<h3 id="hvordan-ser-det-ud">Hvordan ser det ud?</h3>
<p>Hvis vi kigger på MLP(Multi-layer Peceptron) som kan have flere gemte lag. Hvor vi teknisk set kan smide, hvert ord ind fra en sekvens og få et output der afhænger af rækkefølgen.</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnMLP.png" alt="Calculated final model" /></p>

<p>Men da alle deres vægte og bias er inviduelle kan vi ikke kombinere dem. For at kunne kombinere dem og få et lag skal de have ens vægt og bias. Grunden til vi vil kombinere dem er, at kunne have et lag med en given “historik” af tidligere inputs.</p>

<p>Så hvis vi kombinere de 3 lag får vi en Recurrent Neuron:</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnNeuron.png" alt="Calculated final model" /></p>

<p>Som kan ses på billedet kan den tage hele sætningen som et input. Da vi kan holde værdierne internt i den nye block. Da den bare er en kombination af de gemte lag, som stadig relatere til hinanden i form af en lang kæde.</p>

<p>Hvis man folder RNN’en ud vil man se det som beskrevet ovenfor:</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnUnfolded.png" alt="Calculated final model" /></p>

<p>Hvor x er input og y er output. t står for nuværende time step. Et time step er på et tidspunkt i rækkefølgen. F.eks. hvis vi har 4 bogstaver som input {h, e, l, l} vil det første time step være for ‘h’.</p>

<p>I RNN tager vi tidligere udregnet tilstande for vores gemte lag med i overvejelsen. Dvs. vi tager vores tidligere udregnet tilstand og ganger med vores vægte i vores gemte lag plusset vores bias og ligger oveni vores input x ganget med vægtene for input’sne. Dette propper vi ind i en aktiverings funktion som f.eks. tanh. Til sidst får vi noget der kan skriver som:
<code class="language-plaintext highlighter-rouge">ht = tanh((Whh * ht-1 + bias) + (Wxh * xt))</code></p>

<p>Når man har beregnet den nuværende tilstand, kan man udregne resultatet som er vægten for outputtet ganget med den nuværende tistand, så vi kan sige:
<code class="language-plaintext highlighter-rouge">yt = Why * ht</code></p>

<h3 id="trin-for-trin">Trin for trin</h3>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnExInputs.png" alt="RNN Example Inputs" /></p>

<p>Givet vi har inputs {h, e, l, l} som er 1-enkodet som set ovenfor i en bogstavliste af {h, e, l, o} og vi prøver at forudse det næste bogstav i h-e-l-l-?, som gerne skulle give “o” og forme hallo.</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnWxh.png" alt="RNN Example Input Weights" /></p>

<p>Og givet de tilfældige vægte for vægtene fra input til det gemte lag. Som set ovenfor.</p>

<p><strong>Trin 1</strong></p>

<p>Ved første input ganges vægtene med inputtet indtil Recurrent Neuronen. Inputtet er Xt og vægtene for inputtet er Wxh.</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnFirstState.png" alt="RNN First Calculation" /></p>

<p><strong>Trin 2</strong>
Ved Recurrent Neuronen har vi Whh som en vægt på 0,427043 og en bias på 0,56700.</p>

<p>For første input er den tidligere tilstand [0, 0, 0].</p>

<p>Så ved:
<code class="language-plaintext highlighter-rouge">whh * ht-1 + bias</code>
Bliver alle 3 beregninger lig med bias.</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnSecondState.png" alt="RNN First Calculation" /></p>

<p><strong>Trin 3</strong>
Så kan vi beregne den nuværende tilstand med:
<code class="language-plaintext highlighter-rouge">ht = tanh((Whh * ht-1 + bias) + (Wxh * Xt))</code></p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnThirdState.png" alt="RNN Third Calculation" /></p>

<p><strong>Trin 4</strong>
Første tilstand udregnet bliver nu “ht-1” og vi beregner nu for “e” som så er vores Xt.</p>

<p>Vi bruger samme beregning som i “Trin 3”.</p>

<p>Så for “Whh * ht-1 + bias”:</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnFourthState.png" alt="RNN Fourth Calculation" /></p>

<p>Og for “Wxh * xt”:</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnFourthInput.png" alt="RNN Fourth Calculation" /></p>

<p><strong>Trin 5</strong>
Så beregner vi tilstanden / ht for “e”.</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnFithState.png" alt="RNN Fifth Calculation" /></p>

<p>Nu med et nyt ht-1 som bliver taget med i næste beregning forsætter vi sådan.</p>

<p><strong>Trin 6</strong>
For hver tilstand vil RNN’et producere et output. Det kan beregnes som yt med:
<code class="language-plaintext highlighter-rouge">yt = Why * ht</code></p>

<p>Så hvis vi beregner outputtet for “e”.</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnFinalState.png" alt="RNN Final Calculation" /></p>

<p><strong>Trin 7</strong>
Man kan beregne sandsynligheden for et bostav i vores bogstavsliste ved brug af softmax funktionen.</p>

<p>Softmax er brugt til at udregne sandsynligheden for en række givne klasser. Softmax er også kendt som normalized exponential function.
Softmax udgiver en probalility distribution af “K” sandsynligheder som svarende til “K” reele tal i input vektoren.</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnSoftmax.jpg" alt="RNN Probability Calculation" /></p>

<p>Som kan ses er den største sandsynlighed for næste bogstav “h”, men det er ikke korrekt. Dette er fordi vi ikke har lavet noget back propagation endnu og har ikke trænet netværket.</p>

<h3 id="back-propagation-i-et-recurrent-neural-network">Back propagation i et Recurrent Neural Network</h3>

<p>I et RNN ved forward propagation bliver hvert input flyttet fremad ved hvert time step.</p>

<p>Ved back propagation går vi tilbage i tiden igennem time step’sne og ændre vægtene. Derfor bliver det kaldt Back Propagation Through Time (BPTT).</p>

<p>Hvis vi igen kigger på RNN udfoldet kan det nemmere ses:</p>

<p><img src="/assets/img/posts/UnderstandingRNN/rnnUnfolded.png" alt="RNN Unfolded" /></p>

<p>Man bruger cross entropy loss til at beregne fejlmængden. Cross entropy loss er en effektiv måde, at beregne afstanden til den optimale funktions resultat. Det er en måde, at sige, hvis vi har den optimale funktion som giver resultatet “y” som er vores rigtige værdi, vi beregner så, hvor langt vi er fra den funktion.</p>

<p>Så hvis yt er vores resultat vi har forudsagt og ytr er vores rigtige resultat, beregner man fejlmængden med cross entropy loss:</p>

<p>Fejlen ved et time step:
<code class="language-plaintext highlighter-rouge">Et(ytr,yt) = -ytr * log(yt)</code></p>

<p>Da et trænings eksempel oftest er en sekvens eller i dette eksempel et ord. Vil den totale fejlmængde være, hvert time steps fejlmængde summeret:
<code class="language-plaintext highlighter-rouge">E(ytr,yt) = -sum(ytr * log(yt))</code></p>

<p>Hver gradient for hvert time step i det udfoldet netværk bliver beregnet i forhold til vægtene og da de har samme vægte kan de ligges sammen som en total gradient.</p>

<p>Vægtene er så opdateres for båede recurrent neuronen og de tætte lag.</p>

<p>Et udfoldet RNN ligner et NN både i arkitekturen og i back propagation’en, bortset fra vi ligger alle gradienter sammen fra alle steps i stedet.</p>

<p>I et RNN med flere hundrede og måske tusinde bliver det udfoldet netværk meget stort og efter ens logik meget svær, at udregne tilpasningerne. Dette er ikke helt sandt, men jeg kan ikke forklare hvorfor.</p>

<h3 id="vanishing-og-exploding-gradients---problemet">Vanishing og Exploding Gradients - problemet</h3>

<p>RNN kan få 2 problemer ved længere afhængige værdier. F.eks. en lang sætning der handler om en mand eller beskriver ham. Vil de sidste beskrivelser relatere til manden og ikke et andet objekt man omtaler i sætningen.</p>

<p>Her vil man bruge chain rule men, hvis en af værdierne eller “gradients” nærmede sig 0 ville alle andre også hurtigt nærme sig nul pga. den eksponentielle kæde og netværket ville ikke rigtig lære noget af det. Dette er kaldet Vanishing gradient problemet.</p>

<p><img src="/assets/img/posts/UnderstandingRNN/grad_vanishing.jpg" alt="RNN Vanishing Gradient" /></p>

<p>Som kan ses på billedet er, at Vanishing Gradient problemet er basicly, at de tidligere features bliver visket ud og kan ikke ses i enden. Medmindre man gør noget.</p>

<p>Hvor modsat, hvis nogle af gradients værdierne var høje, vil de meget hurtigt alle blive høje igen grundet det eksponentielle. Dette kan dog nemt løses ved at cutte værdierne ved et givet threshhold.</p>

<p>RNN lider derfor af Vanishing gradient problemet ved lange afhængige inputs.</p>

<p>RNN bliver også utroligt svært at træne ved længere sekvenser med afhængig værdier, da i parameterne i den udrollet RNN vil være rigtig mange der skulle udregnes og det bliver derfor en udfordring.</p>

<p>Arkitekturene LSTM(Long Short Term Memory) og GRU(Gated Recurrent Units) can blive brugt til at håndtere Vanishing Gradient problemet.</p>

<h2 id="kilder">Kilder</h2>
<ol>
  <li><a href="https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/">https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/</a></li>
  <li><a href="https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/">https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/</a></li>
</ol>
 
    </div>

    <div id="disqus_thread"></div>

</article>
<script>
    var disqus_config = function () {
        this.page.url = "https://double-em.github.io/machinelearning/2020/03/27/Understanding_RNN/"; /* Replace PAGE_URL with your page's canonical URL variable */
        this.page.identifier = "/machinelearning/2020/03/27/Understanding_RNN"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */
    };


    (function () { /* DON'T EDIT BELOW THIS LINE */
        var d = document,
            s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript></div>
<div class="col-lg-4">
    <div class="card">
        <div class="card-header"> About </div>
        <div class="card-body text-dark">
            <!-- Your Bio -->
            <p> Software Developer / Datamatiker 4. Sem. Student, Produktgruppe 15, Procesvejledning 8, ERFA Machine Learning 2, ERFA DevOps</p><!-- Place this tag where you want the button to render. -->
<a class="github-button" href="https://github.com/zxited" data-size="large" data-show-count="true" aria-label="Star Zxited on GitHub">Star</a></div>
    </div>
    <div class="card">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <!-- sidebar-horizontal-1 -->
        <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-7259836434848202"
             data-ad-slot="7549410045"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
        <script>
             (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
    </div>
    <div class="card">
        <div class="card-header">Categories </div>
        <div class="card-body text-dark">
             
            <div id="#Laeringsplaner"></div>
            <li class="tag-head">
                <a href="/blog/categories/Laeringsplaner">Laeringsplaner</a>
            </li>
            <a name="Laeringsplaner"></a>

             
            <div id="#MachineLearning"></div>
            <li class="tag-head">
                <a href="/blog/categories/MachineLearning">MachineLearning</a>
            </li>
            <a name="MachineLearning"></a>

             
            <div id="#DevOps"></div>
            <li class="tag-head">
                <a href="/blog/categories/DevOps">DevOps</a>
            </li>
            <a name="DevOps"></a>

            </div>
    </div>
</div></div> <!-- End of row-->
    

    

        </div>
<footer>

    <!--<p> Powered by<a href="https://devlopr.netlify.com/readme"> devlopr jekyll</a>. Hosted at <a href="https://pages.github.com">Github</a>. Subscribe via
        <a href=" /feed.xml ">RSS</a>
    </p>-->

    <p>&copy;2020 - Project blog for school performance reporting.</p>

</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
</div>
</body>

<div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div>
<script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script>
</html>
