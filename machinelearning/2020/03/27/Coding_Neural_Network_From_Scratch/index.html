<!DOCTYPE html>
<html lang=" en "><head>
  <meta charset="utf-8">
  <title>Mike Meldgaard - Software Developer / Datamatiker Student</title>
  <meta http-equip="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Software Developer">
  <link rel="stylesheet" href="https://double-em.github.io/assets/css/main.css" />
  <link rel="stylesheet" href="https://double-em.github.io/assets/css/custom-style.css" />
  <link rel="icon" href="https://double-em.github.io/assets/img/favicon.ico" type="image/gif" sizes="16x16">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.2/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
    integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css"
    integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css"
    integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">
  <!-- Including Snipcart -->
  <link rel="stylesheet" href="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.css" />
  <!-- Including InstantSearch.js library and styling -->
  <!--<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.20.1/moment.min.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">
  <link rel="stylesheet" type="text/css"
    href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch-theme-algolia.min.css">
  <script>
    (function (d, h, m) {
      var js, fjs = d.getElementsByTagName(h)[0];
      if (d.getElementById(m)) { return; }
      js = d.createElement(h); js.id = m;
      js.onload = function () {
        window.makerWidgetComInit({
          position: "right",
          widget: "ofeeof264otl2l5g-zspk40eq2gaomj2n-higi2qphmveubksi"
        })
      };
      js.src = "https://makerwidget.com/js/embed.js";
      fjs.parentNode.insertBefore(js, fjs)
    }(document, "script", "dhm"))
  </script>-->

  

</head><body>
    <div class="container-fluid"><header>

    <div class="col-lg-12">
        <div class="row">
            <div class="col-md-2 center">
                <a href="/">
                    <img src="/assets/img/noimage.jpg" class="profile-img">
                </a>
            </div>
          
            <div class="col-md-4" id="author_details">
                <h1 class="profile-name"> Mike Meldgaard</h1>
                <p class="profile-bio"> Software Developer / Datamatiker Student</p>
                <p class="profile-links">
                    
                    
                    
                    
                    
                    <a class="social-link" href="http://github.com/Zxited">
                        <i class="fab fa-github"></i>
                    </a>
                    
                    
                    
                    
                </p>

            </div>
            <div class="col-md-6 center">
     
                    <ul class="nav justify-content-end" id="navigation">
                    
                    <li class="nav-item">
                        <a class="nav-link" href="/">About</a>
                    </li>
                     
                    <li class="nav-item">
                        <a class="nav-link" href="/blog">Portefølje</a>
                    </li>
                     
                     <!--<li class="nav-item">
                         <a class="nav-link" href="https://double-em.github.io/search/"><i class="fa fa-search" aria-hidden="true"></i></a>
                     </li>-->
                     <!--<li class="nav-item">
                         <button class="header__checkout snipcart-checkout">

                                <svg width="31" height="27" viewBox="0 0 31 27" fill="none" xmlns="http://www.w3.org/2000/svg">
                                  <path
                                    d="M1.10512 0.368718C0.560256 0.368718 0.118164 0.812066 0.118164 1.35848C0.118164 1.9049 0.560256 2.34824 1.10512 2.34824H4.90887L8.30138 18.4009C8.43503 19.0053 8.83085 19.5079 9.32946 19.5041H25.7788C26.3005 19.5118 26.7799 19.0375 26.7799 18.5143C26.7799 17.9911 26.3006 17.5168 25.7788 17.5245H10.1315L9.71003 15.545H27.095C27.5371 15.5412 27.9547 15.2048 28.0511 14.7718L30.354 4.87412C30.4825 4.29933 29.9852 3.67172 29.3979 3.66786H7.21171L6.6771 1.15221C6.58329 0.71276 6.15921 0.368652 5.7107 0.368652L1.10512 0.368718ZM7.623 5.64746H12.7634L13.2569 8.61674H8.25005L7.623 5.64746ZM14.7785 5.64746H20.9881L20.4946 8.61674H15.2719L14.7785 5.64746ZM23.0031 5.64746H28.1537L27.4649 8.61674H22.5097L23.0031 5.64746ZM8.67181 10.5963H13.5862L14.0797 13.5656H9.29919L8.67181 10.5963ZM15.6009 10.5963H20.1656L19.6721 13.5656H16.0944L15.6009 10.5963ZM22.1807 10.5963H27.0023L26.3135 13.5656H21.6872L22.1807 10.5963ZM12.6197 20.164C10.8141 20.164 9.32979 21.6525 9.32979 23.4632C9.32979 25.2739 10.8141 26.7624 12.6197 26.7624C14.4252 26.7624 15.9095 25.2739 15.9095 23.4632C15.9095 21.6525 14.4252 20.164 12.6197 20.164ZM22.4892 20.164C20.6837 20.164 19.1994 21.6525 19.1994 23.4632C19.1994 25.2739 20.6837 26.7624 22.4892 26.7624C24.2948 26.7624 25.7791 25.2739 25.7791 23.4632C25.7791 21.6525 24.2948 20.164 22.4892 20.164ZM12.6197 22.1435C13.3586 22.1435 13.9356 22.7222 13.9356 23.4632C13.9356 24.2042 13.3586 24.7829 12.6197 24.7829C11.8807 24.7829 11.3037 24.2042 11.3037 23.4632C11.3037 22.7222 11.8807 22.1435 12.6197 22.1435ZM22.4892 22.1435C23.2282 22.1435 23.8052 22.7222 23.8052 23.4632C23.8052 24.2042 23.2282 24.7829 22.4892 24.7829C21.7503 24.7829 21.1733 24.2042 21.1733 23.4632C21.1733 22.7222 21.7503 22.1435 22.4892 22.1435Z"
                                    fill="#9094FF" class="header__checkout-fill"></path>
                                </svg>
                                <span class="snipcart-items-count"></span>
                                <span class="snipcart-total-price"></span>
                              </button>
                        </li>-->
                    </ul>
      
            </div>
        </div>
    </div>

</header><div class="col-lg-12">
          
            <!-- Blog Post Breadcrumbs --><nav aria-label="breadcrumb" role="navigation">
        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="/blog">Blog</a>
            </li>
            <li class="breadcrumb-item">
                <a href="/blog/categories">Categories</a>
            </li>
            <li class="breadcrumb-item active" aria-current="page">Forståelse og Kodning af Neuralt Netværk fra bunden i Python</li>
        </ol>
    </nav>
<div class="row">

        <div class="col-lg-8"><article class="card" itemscope itemtype="http://schema.org/BlogPosting">
    <div class="card-header">
        <!-- <h1 class="post-title" itemprop="name headline">Forståelse og Kodning af Neuralt Netværk fra bunden i Python</h1> -->
        <h4 class="post-meta">Kodning af Neuralt Netværk fra bunden i Numpy med Full Batch Gradient Decent</h4>
        <p class="post-summary">Posted by : 
            <img src="/assets/img/noimage.jpg" class="author-profile-img">
            <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                <span itemprop="name">Mike Meldgaard</span>
            </span> at
            <time datetime="2020-03-27 00:00:00 +0000" itemprop="datePublished">Mar 27, 2020</time>
        </p>
        <span class="disqus-comment-count" data-disqus-identifier="/machinelearning/2020/03/27/Coding_Neural_Network_From_Scratch/"></span>     
        <div class="post-categories">
            
            Category : 
            <a href="/blog/categories/MachineLearning">MachineLearning</a>
             
        </div>
    </div>

    <div class="card-body" itemprop="articleBody">
        <!--<img class="card-img-top" src="/assets/img/posts/development.png" alt=""> 
        <br/> <br/>-->
        <h3 id="forståelse-og-kodning-af-neuralt-netværk-fra-bunden">Forståelse og Kodning af Neuralt Netværk fra bunden</h3>

<p>Et neuralt netværk er en sammesætning af neuroner. Det tager flere input. Som går gennem flere gemte lag.</p>

<p>Grundstenen for neurale netværk er en Perceptron. En perceptron  tager flere input og producere et output.</p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/Perceptron.png" alt="Perceptron" /></p>

<p>Tag ovenstående illustration af en Perceptron ville have 3 input værdier kaldet x1, x2, x3 og en vægt til hvert input kaldet w1, w2, w3. Samtidig har en Perceptron en Bias som er en værdi vi kan bruge til at tilpasse funktionen, så vi kan opnå et bedre fit på dataen med vores forudsigelse. Bias har en vægt af 1. Så vi bruger Bias værdien direkte uden at blive vægtet.</p>

<p>Dvs. hvis vi skriver denne Perceptrons linære repræsentation får vi <strong>(w1x1 + w2x2 + w3x3 + 1b)</strong>, hvor vi kan sætte et threshold på 0 for, at udregne resulatet, så vi får <strong>w1x1+w2x2+w3x3+1b&gt;0</strong>.</p>

<p>Perceptrons er linære og blev viderudviklet til Kunstige Neuroner som gør brug af ikke-linære aktiverings funktioner.</p>

<h4 id="aktiverings-funktioner">Aktiverings Funktioner</h4>
<p>Der findes flere aktiverings funktioner som f.eks. nedenstående:</p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/AktivationFunc.png" alt="Activation Functions" /></p>

<p>Aktiverings funktioner giver os muligheden for at estimere eller tilpasse ikke linære eller komplekse funktioner for at få et bedre aktiverings punkt for neuronen.</p>

<h4 id="forward-propagration-back-propagration-og-epochs">Forward Propagration, Back Propagration og Epochs</h4>
<p>Når man får netværket til at udregne resultatet kaldes det Forward Propagation.</p>

<p>Back Propagation bruges til at indstille vægtene og bias værdierne på baggrund af fejlmængden/tabet også kaldet Cost Function af vores Output lag.</p>

<p>En iteration af Forward og Back Propagration er kaldet en trænings iteration aka Epoch.</p>

<h4 id="multi-layer-perception-mlp">Multi-layer perception (MLP)</h4>
<p>MLP kan have flere gemte lag imellem input og output lagene. Som åbner en masse muligheder for mere avanceret og komplekse modeller.</p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/MLP.png" alt="Activation Functions" /></p>

<p>MLP er fuldt forbundet hvilket betyder, at alle noder I hvert lag undtagen input og output – lagene er fuldt fobundet med hver node i tidligere og næste lag.</p>

<h4 id="gradient-decent">Gradient Decent</h4>
<p>Er en træningsalgoritme findes to varianter</p>
<ul>
  <li>Full Batch Gradient Descent (Full Batch)</li>
  <li>Stochastic Gradient Descent (SGD)</li>
</ul>

<p><strong>Full Batch:</strong> Bruger hele træningsættet per vægt. F.eks. man har 10 datapunkter og 2 vægte. Der bruger den alle 10 punkter til at beregne w1 og igen alle 10 punkter til w2.</p>

<p><strong>SGD:</strong> Bruger 1 til flere men aldrig hele sættets datapunkter til en vægt. Dvs. At vi bruge måske punkt 1 til vægt 1 og derefter punkt 1 til vægt 2. Vi kan også bruge flere punkter til hver vægt.</p>

<p>Trænings algoritmer er brugt til at minimere Cost funktionen.</p>

<h4 id="trin-for-trin-hvordan-et-neuralt-netværk-fungere-med-full-batch">Trin for trin hvordan et Neuralt Netværk fungere med Full Batch</h4>
<p>Hvis vi tager følgende netværk</p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNExample.png" alt="Neural Network Example" /></p>

<p>Hvert tal ud fra en streg er en vægt og hver streg til en b - værdi er nodens bias.</p>

<p><strong>Trin 1.</strong>
Vi starter med at indsætte vores 3 input, de 3 resultater og vælger nogle tilfælidge vægte og bias.</p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNTable1.png" alt="Neural Network Example" /></p>

<p>X = Inputs
y = Outputs</p>

<p>wh = Wheights for Hidden layer
bh = Bias for Hidden layer</p>

<p>wout = Weights for Output layer
bout = Bias for Output layer</p>

<p><strong>Trin 2</strong>
Vi udregner inputværdierne til Hidden layer, som gøres ved at gange inputs med vægtene plusset med vores bias.</p>

<p>F.eks. ved første input runde(In 1) som har værdierne 1, 0, 1, 0. Der tager vi værdierne og ganger med hver vægt(0.42, 0.10, 0.60, 0.92) til første gemte node(Rød) og samler i et total som vi plusser med vores bias for første gemte node(Rød) som giver os vores input til den node for første runde.</p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NN_Table_Matrix_Dot_Product.png" alt="Table Matrix Dot Prodcut Example" /></p>

<p>Så vi får for at beregne alle værdier:
<code class="language-plaintext highlighter-rouge">hidden_layer_input = matrix_dot_product(X,wh) + bh</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/HiddenLayerInput.png" alt="Calculated hidden layer input" /></p>

<p><strong>Trin 3</strong>
Vi bruger Sigmoid som ikke-linær transformations funktions(aktiverings funktion) og den kan beskrives som:
<code class="language-plaintext highlighter-rouge">1/(1 + exp(-x))</code>
Exp() står for eksponentiel funktion som python har. Det gør vores funktion også kan skrives som:
<code class="language-plaintext highlighter-rouge">1/(1 + e^-x)</code>
I tilfælde af man ikke har exp() til rådighed.</p>

<p>Dette gøres for hver værdi, så de alle er mellem 0 og 1.</p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/HiddenLayerActivations.png" alt="Calculated hidden layer activations" /></p>

<p>Dette skriver vi som:
<code class="language-plaintext highlighter-rouge">hidden_layer_activations = sigmoid(hidden_layer_input)</code></p>

<p><strong>Trin 4</strong>
Vi laver så trin 2 og 3 for output i stedet.</p>

<p>Så vi finder først inputtet til output laget ved at gange aktiveringerne i det gemte lag med vægtene til output laget plusset med bias for output laget:
<code class="language-plaintext highlighter-rouge">output_layer_input = matrix_dot_product(hidden_layer_activations * wout) + bout</code></p>

<p>Derefter transformere vi tallet igen ved hjælp af vores aktiverings funktion for at få et tal mellem 0 og 1.
<code class="language-plaintext highlighter-rouge">output = sigmoid(output_layer_input)</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNTableOutput.png" alt="Calculated Output" /></p>

<p><strong>Tring 5</strong>
Vi beregner graden af fejl ved at trække output fra vores kendte svar:
<code class="language-plaintext highlighter-rouge">E = y-output</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNOutputError.png" alt="Calculated Output Error" /></p>

<p><strong>Trin 6</strong>
Vi beregner nu hældingen / derivatives sigmoid for hver aktivering. Som er hvor følsom funktionen er overfor ændringer på det givet punkt. Slope siger noget om grafens position. Et positivt tal betyder den er stigende fra venstra mod højte. Et negativt tal betyder den er faldende fra venstre mod højre. Jo stærkere positiv eller negativ desto stejlere er grafen i det punkt. Og derfor fortæller den os meget hurtigt, hvor følsom funktionen er lige der.</p>

<p>Derivatives Sigmoid kan skrives som:
<code class="language-plaintext highlighter-rouge">x * (1 – x)</code>
Dette gøres for alle vores akriverings punkter. Dvs. båede output og hidden_layer_activations.</p>

<p><code class="language-plaintext highlighter-rouge">Slope_hidden_layer = derivatives_sigmoid(hidden_layer_activations)</code>
<code class="language-plaintext highlighter-rouge">Slope_output = derivatives_sigmoid(output)</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNSlope.png" alt="Calculated Slopes" /></p>

<p><strong>Trin 7</strong>
Nu beregner vi delta for ouput laget som er den mængde vi skal tilpasse med. Dette gør vi ved at gange fejlgraden med hældningen for hvert output.
<code class="language-plaintext highlighter-rouge">d_output = E * Slope_output</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNDeltaOutput.png" alt="Calculated Delta for Output" /></p>

<p><strong>Trin 8</strong>
Vi beregner så fejlgraden i det gemte lag, da ændringerne skal høres tilbage igennem hele netværket.</p>

<p>Dette gør vi ved at gange ændringen i output laget med vægtene til de tidligere neuroner i det gemte lag.
<code class="language-plaintext highlighter-rouge">Error_at_hidden_layer = matrix_dot_product(d_output, wout.Transpose)</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNErrorHiddenLayer.png" alt="Calculated Error at hidden layer" /></p>

<p>Bemærk det er nødvendigt at lave wout om til wout.T, da hvert inputs ændring i output skal ganges på hver vægt til tidligere neuroner.</p>

<p><strong>Trin 9</strong>
Der skal nu beregnes ændringerne til det gemte lag. Det gør vi ved at gange fejlgarden i det gemte lag med hældningerne i det gemte lag.</p>

<p><code class="language-plaintext highlighter-rouge">d_hiddenlayer = Error_at_hidden_layer * Slope_hidden_layer</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/deltaHiddenLayer.png" alt="Calculated Error at hidden layer" /></p>

<p><strong>Trin 10</strong>
Så opdatere vi vægtene for både output og hidden layer.
Det gør vi ved, at gange de respektive aktiveringsværdier med forskels værdierne ganget en valgt læringsrate og ligge det oveni de nuværende vægte, så vi får:
<code class="language-plaintext highlighter-rouge">wh = wh + matrix_dot_product(X.Transpose, d_hiddenlayer) * learning_rate</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNWHNew.png" alt="Calculated new wh" /></p>

<p><code class="language-plaintext highlighter-rouge">wout = wout + matrix_dot_product(hidden_layer_activations.Transpose, d_output) * learning_rate</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNWoutNew.png" alt="Calculated new wout" /></p>

<p><strong>Trin 11</strong>
Vi mangler kun nu at indstille bias værdierne. Det kan gøres ved at vi tager summen af en kolonne fra en tabel med forskelsværdier(delta) og summere den og ganger med vores læringsrate og ligger oveni den eksisterende tilhørende bias.</p>

<p>Dvs. vi får noget lignende:
<code class="language-plaintext highlighter-rouge">bh = bh + sum(d_hiddenlayer, axis=0) * learning_rate</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/bhnew.png" alt="Calculated new bh" /></p>

<p><code class="language-plaintext highlighter-rouge">bout = bout + sum(d_output, axis=0) * learning_rate</code></p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/boutnew.png" alt="Calculated new bout" /></p>

<p>Vi burde nu have en total model der ser ligeledes sådan ud:</p>

<p><img src="/assets/img/posts/CodingNetworkFromScratch/NNFinalModel.png" alt="Calculated final model" /></p>

<p>Vi har nu kørt en trænings iteration også kaldet Epoch.
Bemærk at Trin 1 - 4 er kendt som “Forward Propagatoin” og Trin 5 - 11 er kendt som “Backward Propagation”.</p>

<p>Alt det forrige kan gøres i kode:
<script src="https://gist.github.com/Zxited/7a9deb05e08a62c4a872636bb59420a6.js"></script></p>

<h3 id="kilder">Kilder</h3>
<ul>
  <li>
    <p><a href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/">https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/</a></p>
  </li>
  <li>
    <p><a href="https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications">https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications</a></p>
  </li>
  <li>
    <p><a href="https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-artificial-neural-network-6a3f2bc0eecb">https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-artificial-neural-network-6a3f2bc0eecb</a></p>
  </li>
</ul>
 
    </div>

    <div id="disqus_thread"></div>

</article>
<script>
    var disqus_config = function () {
        this.page.url = "https://double-em.github.io/machinelearning/2020/03/27/Coding_Neural_Network_From_Scratch/"; /* Replace PAGE_URL with your page's canonical URL variable */
        this.page.identifier = "/machinelearning/2020/03/27/Coding_Neural_Network_From_Scratch"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */
    };


    (function () { /* DON'T EDIT BELOW THIS LINE */
        var d = document,
            s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript></div>
<div class="col-lg-4">
    <div class="card">
        <div class="card-header"> About </div>
        <div class="card-body text-dark">
            <!-- Your Bio -->
            <p> Software Developer / Datamatiker 4. Sem. Student, Produktgruppe 15, Procesvejledning 8, ERFA Machine Learning 2, ERFA DevOps</p><!-- Place this tag where you want the button to render. -->
<a class="github-button" href="https://github.com/zxited" data-size="large" data-show-count="true" aria-label="Star Zxited on GitHub">Star</a></div>
    </div>
    <div class="card">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <!-- sidebar-horizontal-1 -->
        <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-7259836434848202"
             data-ad-slot="7549410045"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
        <script>
             (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
    </div>
    <div class="card">
        <div class="card-header">Categories </div>
        <div class="card-body text-dark">
             
            <div id="#Laeringsplaner"></div>
            <li class="tag-head">
                <a href="/blog/categories/Laeringsplaner">Laeringsplaner</a>
            </li>
            <a name="Laeringsplaner"></a>

             
            <div id="#MachineLearning"></div>
            <li class="tag-head">
                <a href="/blog/categories/MachineLearning">MachineLearning</a>
            </li>
            <a name="MachineLearning"></a>

             
            <div id="#DevOps"></div>
            <li class="tag-head">
                <a href="/blog/categories/DevOps">DevOps</a>
            </li>
            <a name="DevOps"></a>

            </div>
    </div>
</div></div> <!-- End of row-->
    

    

        </div>
<footer>

    <!--<p> Powered by<a href="https://devlopr.netlify.com/readme"> devlopr jekyll</a>. Hosted at <a href="https://pages.github.com">Github</a>. Subscribe via
        <a href=" /feed.xml ">RSS</a>
    </p>-->

    <p>&copy;2020 - Project blog for school performance reporting.</p>

</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
</div>
</body>

<div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div>
<script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script>
</html>
